{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTT3CdbJJeYk"
   },
   "source": [
    "**Beam-ის დაყენება; საჭირო იმპორტები**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wgBPknCq96_M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DataEng\\lib\\site-packages\\apache_beam\\io\\gcp\\bigquery.py\", line 341, in <module>\n",
      "    import google.cloud.bigquery_storage_v1 as bq_storage\n",
      "ModuleNotFoundError: No module named 'google.cloud.bigquery_storage_v1'\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet apache-beam\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import apache_beam as beam\n",
    "import apache_beam as beam\n",
    "\n",
    "from apache_beam.dataframe import convert\n",
    "from apache_beam.dataframe.io import read_csv, to_csv\n",
    "\n",
    "import apache_beam.runners.interactive.interactive_beam as ib\n",
    "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n",
    "\n",
    "# თუ ეს error-ები და warning-ები გექნებათ, შეგიძლიათ დააიგნოროთ: \n",
    "# ERROR: pip's dependency resolver does not currently take into account all the packages that are installed.\n",
    "# ან\n",
    "# WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
    "# WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5ekVqEHkK4HC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: apache-beam\n",
      "Version: 2.34.0\n",
      "Summary: Apache Beam SDK for Python\n",
      "Home-page: https://beam.apache.org\n",
      "Author: Apache Software Foundation\n",
      "Author-email: dev@beam.apache.org\n",
      "License: Apache License, Version 2.0\n",
      "Location: c:\\programdata\\anaconda3\\envs\\dataeng\\lib\\site-packages\n",
      "Requires: avro-python3, crcmod, dill, fastavro, future, grpcio, hdfs, httplib2, numpy, oauth2client, orjson, protobuf, pyarrow, pydot, pymongo, python-dateutil, pytz, requests, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show apache_beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvlhZ8gVQbwb"
   },
   "source": [
    "# **ამოცანები**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTXe-i-gQ8OX"
   },
   "source": [
    "**ამოცანა #1 - სტუდენტების საბოლოო ნიშნების დათვლა**\n",
    "*(1 ქულა)*\n",
    "\n",
    "ამ ამოცანის მიზანია, რამოდენიმე სტუდენტისთვის ერთ-ერთი საგნის ფინალური ქულა დავთვალით და გავიგოთ, ჩააბარა თუ არა სტუდენტმა ეს საგანი. კრიტერიუმები მარტივია და სულ ორი კომპონენტია:\n",
    "\n",
    " 1) შუალედური გამოცდა, რომლის ქულებიც თითოეული სტუდენტისთვის მოცემულია midterm_grades ცვლადში. ეს არის tuple-ების მასივი. tuple-ის პირველი ელემენტია სტუდენტის სახელი, მეორე - გამოცდაში მიღებული ქულა;\n",
    " \n",
    " 2) ფინალური პროექტი, რომლის ქულებიც თითოეული სტუდენტისთვის მოცემულია project_grades ცვლადში. ესეც არის tuple-ების მასივი. \n",
    "\n",
    "საგნის ჩააბარების კრიტერიუმი: თუ სტუდენტის საშუალო ქულა 50.0-ია, მაშინ ვთვლით, რომ სტუდენტმა საგანი ჩააბარა.\n",
    "\n",
    "ამოცანაში უნდა დაითვალოთ სტუდენტების საშუალო ქულა ორივე კომპონენტში და საბოლოო შედეგი წარმოადგინოთ pcollection-ის სახით. ამ კოლექციის თითოეული ელემენტი უნდა იყოს დაფორმატებული ასეთნაირად:\n",
    "\n",
    "*Student1 has passed the subject with avg grade of 100.0*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "ამოცანა უნდა შეასრულოთ Beam-ის გამოყენებით. ამისთვის გაწვდით მინიმალისტურ ამოხსნას (უფრო სტრუქტურას), რომელიც თქვენ უნდა გაარჩიოთ და დაასრულოთ. გაითვალისწინეთ:\n",
    " * ამოხსნის ძირითადი ჩონჩხი უკვე აწყობილია. თქვენ საწყისი pcollection-ები სწორად უნდა დააგენერიროთ და დაასრულოთ apply_transforms ფუნქციის იმპლემენტაცია. apply_transforms არის ის ადგილი, სადაც ყველა მოთხოვნილი ტრანფორმაცია ხდება pcollection-ებზე.\n",
    " * ფორმატირებისთვის უნდა დაიხმაროთ კლასი StudentGrade. რა თქმა უნდა, მისი იმპლემენტაციაც თქვენი მოსაფიქრებელია. 🐱‍💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GYzvslNULppU"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student1 has passed the subject with avg grade of 100.0\n",
      "Student2 has passed the subject with avg grade of 50.0\n",
      "Student4 has failed the subject with avg grade of 45.0\n",
      "Student5 has failed the subject with avg grade of 49.5\n",
      "Student3 has failed the subject with avg grade of 37.5\n"
     ]
    }
   ],
   "source": [
    "midterm_grades = [('Student1', 100.0),('Student2', 50.0),('Student3', 75.0)]\n",
    "project_grades = [('Student1', 100.0),('Student2', 50.0),('Student4', 90.0),('Student5', 99.0)]\n",
    "\n",
    "PASSING_GRADE = 50.0\n",
    "\n",
    "class StudentGrade:\n",
    "  \n",
    "    def __init__(self, student_name, midterm_grade, project_grade):\n",
    "        self.student_name = student_name\n",
    "        self.midterm_grade = midterm_grade\n",
    "        self.project_grade = project_grade\n",
    "        self.avg_grade = (midterm_grade + project_grade) / 2.0\n",
    "\n",
    "    def __str__(self):\n",
    "        res = self.student_name + ' has'\n",
    "        res += ' failed' if self.avg_grade < 50.0 \\\n",
    "                else ' passed'\n",
    "        res += ' the subject with avg grade of ' + str(self.avg_grade)\n",
    "        return res\n",
    "\n",
    "def apply_transforms(midterm_grades, project_grades):\n",
    "    def createStudent(cgbk):\n",
    "        student_name, grades = cgbk\n",
    "        if not grades['Midterm']: grades['Midterm'].append(0.0)\n",
    "        if not grades['Project']: grades['Project'].append(0.0)\n",
    "        return StudentGrade(student_name, grades['Midterm'][0], grades['Project'][0])\n",
    "    \n",
    "    grouped = ({'Midterm': midterm_grades, 'Project': project_grades} | beam.CoGroupByKey())\n",
    "    return (grouped | beam.Map(createStudent))\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    \n",
    "  midterms = p | 'Midterm Grades' >> beam.Create(midterm_grades)\n",
    "  projects = p | 'Project Grades' >> beam.Create(project_grades)\n",
    "  (\n",
    "      apply_transforms(midterms, projects)\n",
    "      | beam.Map(print)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJdY-Xc_ggLJ"
   },
   "source": [
    "**ამოცანა #2 - ისევ და ისევ Marvel and DC: the good and the bad**\n",
    "*(2 ქულა)*\n",
    "\n",
    "\n",
    "უნდა ვიპოვოთ Top 10 ყველაზე ძლევამოსილი პერსონაჟი Marvel-ისა და DC-ის სამყაროებიდან Beam-ის გამოყენებით.\n",
    "\n",
    "Dataset არის თქვენთვის უკვე ნაცნობი (ავად თუ კარგად 😁). სულ გვაქვს ორი csv ფაილი:\n",
    "* characters_info.csv - პერსონაჟების შესახებ მონაცემები (სახელი, კეთილია/ბოროტია, სქესი, ფიზიკური აღწერილობა, რომელი სამყაროს ნაწილია და ა. შ. ველები: Name, Alignment, Gender, EyeColor, Race, HairColor,\tPublisher,\tSkinColor,\tHeight, Weight;\n",
    "* character_stats.csv - სხვადასხვა პერსონაჟის სტატისტიკური მონაცემები ველებით Name, Alignment, Intelligence, Strength, Speed, Durability, Power, Combat, Total (ჯამური ქულა ყველა კომპონენტში);\n",
    "\n",
    "დუბლირებებზე შეგიძლიათ არ იდარდოთ. ასევე, რა პერსონაჟებიც არიან ერთ ფაილში, იგივე პერსონაჟებია მეორეშიც და პირიქით. ფაილებში პერსონაჟები არა მარტო მარველის ან dc-ის, არამედ სხვა სამყაროებიდანაცაა (Tolkien, Harry Potter...) .\n",
    "\n",
    "რომ დავაკონკრეტოთ ამოცანა:\n",
    "  * უნდა მოვძებნოთ Top 10 ყველაზე ძლევამოსილი პერსონაჟები მხოლოდ და მხოლოდ Marvel-ის ან DC-ის სამყაროებიდან. რაც უფრო მაღალია Total ველის მნიშვნელობა (stats ფაილი), მით უფრო ძლევამოსილია პერსონაჟი;\n",
    "  * გვაინტერესებს Top 10 ყველაზე ძლევამოსილი პერსონაჟი როგორც კეთილ გმირებში (alignment = 'good'), ასევე ბოროტებში (alignment = 'bad') **ცალ-ცალკე**. ანუ ტოპ 10 ყველაზე ძლიერი, კეთილი პერსონაჟი და იგივე ბოროტებისთვისაც. ყველა სხვა alignment არ გვაინტერესებს;\n",
    "  * საბოლოო შედეგში გვინდა, რომ გვქონდეს მხოლოდ შემდეგი ველები: name, score (იგივე, რაც Total ველი), gender, race, universe. ეს შედეგები თითოეული aligment-ისთვის უნდა შევინახოთ ცალ-ცალკე ფაილში: top_10_bad_heroes.csv და top_10_good_heroes.csv. ანუ სულ ეს ორი output ფაილი გვექნება. ათეული დალაგებული უნდა იყოს score-ის კლებადობის მიხედვით.\n",
    "\n",
    "\n",
    "**ტექნიკური დეტალები:**\n",
    " \n",
    " ამოხსნა მთლიანად თქვენს ფანტაზიაზეა, მაგრამ გარკვეულ რჩევებს მაინც მოგცემთ:\n",
    " * ამ ამოცანას უფრო იოლად ამოხსნით, თუ dataframe-ებს გამოიყენებთ;\n",
    " * იმისთვის, რომ dataframe-ები ვიზუალურად ნახოთ, დაგჭირდებათ Interactive Beam და მისი Runner, რომელთა შესაბამისი იმპორტებიც უკვე უზრუნველყოფილია. ***ib.collect(df)***-ით შეძლებთ dataframe ნახოთ საჭიროების შემთხვევაში. Pipeline-ის დასაწყისი დატოვეთ ისე, როგორც მოგაწოდეთ;\n",
    " * Beam-ის DataFrame-ები Pandas-ისას სინტაქსურად ძალიან ჰგავს, ოღონდ გარკვეული შეზღუდვებიც აქვს. მაგალითად, ინდექსების გარეშე Beam-ს პრობლემები აქვს ზოგ სიტუაციაში (თუნდაც merge-ისას) და ამის გამო გარკვეული exception-ები შეიძლება გქონდეთ. ამიტომ ინდექსები გაითვალისწინეთ;\n",
    " * მნიშვნელოვანი საკითხი: Beam-ის Pipeline-ში არც ერთი ოპერაციის label არ უნდა მეორდებოდეს. თუ რაღაც მიზეზებით ერთი და იგივე ტრანსფორმაცია ორჯერ გაქვთ ფაიფლაინში და სახელი საერთოდ არ მიუთითეთ, default-ად ერთსა და იმავე სახელს მიანიჭებს Beam და გექნებათ exception. ამიტომ გაითვალისწინეთ, რომ სხვადასხვა label უნდა მიუწეროთ ყველა ტრანსფორმაციას. Label-ები ორნაირად შეიძლება მიეთითოს, სიტუაციიდან გამომდინარე. მაგალითად: **pipeline | 'ლეიბლის უნიკალური სახელი' >> ტრანსფორმაცია**  ან **beam.Map(..., label='უნიკალური სახელი')**;\n",
    " * class Alignment(Enum): უბრალოდ enum-ია, სადაც alignment-ები გვაქვს გადანომრილი. აუცილებელი არაა გამოყენება, სურვილისამებრ;\n",
    " * Top 10 პერსონაჟის საპოვნელად, სავარაუდოდ, დაგჭირდებათ beam.transforms.combiners მოდულის ფუნქციები. თუ სხვა იდეა არ გექნებათ, მაგალითად, შეგიძლიათ ნახოთ აი, ეს ფუნქცია: [Top.Of](https://beam.apache.org/releases/pydoc/2.2.0/apache_beam.transforms.combiners.html#apache_beam.transforms.combiners.Top). [სხვა მაგალითებიც](http://beam.apache.org/documentation/transforms/python/aggregation/top/)\n",
    " * აუცილებელი არაა, მაგრამ ყოველი შემთხვევისთვის: თუ თქვენი solution-ის რაღაც მომენტში გექნებათ სიტუაცია, სადაც pipeline-ში გაქვთ pcollection სიის სახით და გინდათ, მიიღოთ სათითაოდ ყველა ელემენტი ამ სიაში, შეგიძლიათ, გამოიყენოთ ჩვენ მიერ მოწოდებული პაწაწინა კლასი BreakList;\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaRE2sG5PKzk"
   },
   "outputs": [],
   "source": [
    "class Alignment(Enum):\n",
    "  bad = 0 \n",
    "  good = 1\n",
    "  neutral = 2\n",
    "  undefined = 3\n",
    "\n",
    "class BreakList(beam.DoFn):\n",
    "  def process(self, element):\n",
    "    for e in element:\n",
    "      yield e\n",
    "\n",
    "\n",
    "with beam.Pipeline(InteractiveRunner()) as pipeline:\n",
    "    characters_info_df = pipeline | 'Read characters info CSV' >> beam.dataframe.io.read_csv('./characters_info.csv')\n",
    "    characters_stats_df = pipeline | 'Read character stats CSV' >> beam.dataframe.io.read_csv('./character_stats.csv')\n",
    "    \n",
    "    characters_stats_total_df = characters_stats_df.loc[:, ['Name', 'Total']]\n",
    "    characters_stats_total_df['Name1'] = characters_stats_total_df['Name']\n",
    "    characters_info_pruned_df = characters_info_df.loc[:, ['Name', 'Alignment', 'Gender', 'Race', 'Publisher']]\n",
    "    \n",
    "    merged = characters_stats_total_df.set_index('Name1').merge(characters_info_pruned_df.set_index('Name'), left_index=True, right_index=True)\n",
    "    \n",
    "    merged_marvel = merged[merged['Publisher'] == 'Marvel Comics']\n",
    "    marvel_good = merged_marvel[merged_marvel['Alignment'] == 'good']\n",
    "    marvel_bad = merged_marvel[merged_marvel['Alignment'] == 'bad']\n",
    "    \n",
    "    marvel_good_top10 = (convert.to_pcollection(marvel_good)\n",
    "                         | 'Get top 10 good by total' >> beam.combiners.Top.Of(10, key=lambda row: row[1], reverse=False)\n",
    "                         | 'Break list top 10 good' >> beam.ParDo(BreakList()))\n",
    "    marvel_good_top10 = marvel_good_top10 | 'Write out schema for top 10 good' >> beam.Map(\n",
    "                             lambda row: beam.Row(\n",
    "                                 name = row[0],\n",
    "                                 score = row[1],\n",
    "                                 gender = row[3],\n",
    "                                 race = row[4],\n",
    "                                 universe = row[5]\n",
    "                             ))\n",
    "    \n",
    "    marvel_bad_top10 = (convert.to_pcollection(marvel_bad)\n",
    "                         | 'Get top 10 bad by total' >> beam.combiners.Top.Of(10, key=lambda row: row[1], reverse=False)\n",
    "                         | 'Break list top 10 bad' >> beam.ParDo(BreakList()))\n",
    "    marvel_bad_top10 = (marvel_bad_top10 | 'Write out schema for top 10 bad' >> beam.Map(\n",
    "                             lambda row: beam.Row(\n",
    "                                 name = row[0],\n",
    "                                 score = row[1],\n",
    "                                 gender = row[3],\n",
    "                                 race = row[4],\n",
    "                                 universe = row[5]\n",
    "                             ))\n",
    "                        | beam.Reshuffle())\n",
    "    \n",
    "    marvel_good_top10_df = convert.to_dataframe(marvel_good_top10)\n",
    "    marvel_good_top10_df = marvel_good_top10_df.set_index('name')\n",
    "    marvel_good_top10_df.to_csv('./top_10_good_heroes')\n",
    "    \n",
    "    marvel_bad_top10_df = convert.to_dataframe(marvel_bad_top10)\n",
    "    marvel_bad_top10_df = marvel_bad_top10_df.set_index('name')\n",
    "    marvel_bad_top10_df.to_csv('./top_10_bad_heroes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VKBwXzIS5MZ"
   },
   "source": [
    "**ამოცანა #3 - Breaking News**\n",
    "*(3 ქულა)*\n",
    "\n",
    "დატასეტში bbc_news.csv მოცემული გვაქვს 1500-მდე მოკლე სტატია BBC News-იდან. თითოეულ სტატიას აქვს უნიკალური ID და კატეგორიის label-ი (tech, business, politics, entertainment, sport).\n",
    "\n",
    "მიზანია, რომ თითოეულ სტატიას დავუგენერიროთ tag-ები შემდეგი მარტივი კრიტერიუმით:  უნდა მოვძებნოთ 3 ყველაზე ხშირი სიტყვა ამ სტატიაში. აუცილებელია, რომ თითოეული სიტყვა მინიმუმ 10-ჯერ მაინც გვხვდებოდეს კონკრეტულ სტატიაში.\n",
    "\n",
    "გაითვალისწინეთ, რომ:\n",
    " * Tag-ები არ უნდა იყოს ე.წ. stopword-ები ან სიმბოლოები. მათი ჩამონათვალი არის ფაილში stopwords.txt;\n",
    " * Tag-ები არ შეიძლება იყოს რიცხვები;\n",
    " * Tag-ები არ შეიძლება იყოს ერთ ან ორ სიმბოლოიანი სიტყვები;\n",
    " * სიტყვებად ჩავთვალოთ შემდეგი სიმბოლოებით დაყოფილი ტოკენები: \n",
    "\n",
    "          whitespace\n",
    "\n",
    "          ,\n",
    "\n",
    "          :\n",
    "\n",
    "          !\n",
    "\n",
    "          ?\n",
    "\n",
    " * ტრანსფორმაციები უნდა შეასრულოთ, რასაკვირველია, Beam-ის გამოყენებით და არა უბრალოდ პითონის ხარჯზე. 😏\n",
    "\n",
    "საბოლოო resultset უნდა ჩაწეროთ csv ფაილად და უნდა შედგებოდეს ველებისგან: ***ArticleID, Category, Tag, Frequency***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-Af8bLwTDp5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with beam.Pipeline(InteractiveRunner()) as pipeline:\n",
    "    news_df = pipeline | 'Read news CSV' >> beam.dataframe.io.read_csv('./bbc_news.csv')\n",
    "    stopwords_txt = open('./stopwords.txt', 'r')\n",
    "    stopwords = stopwords_txt.read().split('\\n')\n",
    "    news_pc = convert.to_pcollection(news_df)\n",
    "    news_filtered = (news_pc | 'Split text' >> beam.Map(lambda row: (row[0], re.split(': |\\! |\\? |\\, | |\\. ', row[1]), row[2]))\n",
    "                     | 'Filter words' >> beam.Map(lambda row: (row[0], row[1] | beam.Filter(lambda x: (x not in stopwords and not (isinstance(x, int) or isinstance(x, float)) and len(x) > 2)), row[2]))\n",
    "                     | 'Get element counts' >> beam.Map(lambda row: (row[0], row[1] | beam.combiners.Count.PerElement(), row[2]))\n",
    "                     | 'Filter by count (>=10)' >> beam.Map(lambda row: (row[0], row[1] | beam.Filter(lambda x: x[1] >= 10), row[2]))\n",
    "                     | 'Get top 3' >> beam.Map(lambda row: (row[0], row[1] | beam.combiners.Top.Of(3, key=lambda a: a[1], reverse=False), row[2]))\n",
    "                     | 'Filter rows without tags' >> beam.Filter(lambda row: len(row[1][0]) > 0)\n",
    "                     | 'Remove nested list' >> beam.Map(lambda row: beam.Row(ArticleID=row[0], TagFreq=row[1][0], Category=row[2])))\n",
    "    news_filtered_df = convert.to_dataframe(news_filtered)\n",
    "    news_exp_df = news_filtered_df.explode('TagFreq')\n",
    "    news_exp_pc = convert.to_pcollection(news_exp_df) | 'Separate columns' >> beam.Map(lambda row: beam.Row(ArticleID=row[0], Category=row[2], Tag=row[1][0] if row[1] != '-' else '-', Frequency=row[1][1] if row[1] != '-' else '-'))\n",
    "    news_final_df = convert.to_dataframe(news_exp_pc)\n",
    "    news_final_df = news_final_df.set_index('ArticleID')\n",
    "    news_final_df.to_csv('./resultset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "745De2WwWe_D"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "შესრულებული დავალება მოგვაწოდეთ ნოუთბუქის სახით.\n",
    "წარმატებები!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3 Beam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
