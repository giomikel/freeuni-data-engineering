diagram.pdf ფაილში არის hive ცხრილების დიაგრამა.

movies dataset-ის csv ფაილების დირექტორიის მისამართი: hdfs://namenode:8020/DataLake/archive

Airflow Variables		ჩემი value-ები გასატესტად
num_posters_to_download		100
num_download_processes		5
num_epochs			10
poster_to_predict_path		poster.jpg

docker ფაილში წესით ყველა ბიბლიოთეკაა დამატებული, რაც გამოვიყენე


აღწერასავით

credits და ratings csv ფაილები 64MB-ს აჭარბებდა და file browser არ იძლეოდა ატვირთვის საშუალებას, 
ამიტომ csv splitter-ით რამდენიმე ნაწილად დავყავი და ისე ავტვირთე შესაბამისად DataLake/archive/credits 
და DataLake/archive/ratings დირექტორიებში. სპარკის read-ში თვითონ დირექტორიები მივუთითე და 
მასში არსებული ყველა ფაილი გააერთიანა dataframe-ში.

სანამ პოსტერების გადმოწერას დავიწყებდი, შემდეგი task-ით ფილმების imdb id და შესაბამისი ჟანრები csv ფაილში 
ჩავწერე /airflow/data/movie_genres.csv მისამართზე, რომ ყოველ პარალელურ პროცესში სპარკით hdfs-დან 
არ წამომეღო ცხრილები. ამ task-სთვის variable-ად დავამატე num_posters_to_download სადაც ვუთითებ რამდენი
პოსტერი მქონდეს ჯამურად (უნიკალურები არა) მოდელის training-სთვის.

გადმოწერის ნაწილისთვის variable-ად დავამატე num_download_processes რომელსაც ვიყენებ გადმოწერის პროცესების
რაოდენობის განსასაზღვრად. პარალელიზმისთვის მანამდე ტოლ ნაწილებად ვყოფ პოსტერების რაოდენობას და ვითვლი 
შესაბამის ინდექსებს csv ფაილში, თუ რომლები გადმოიწეროს თითო პროცესმა.
პოსტერები /airflow/data/images დირექტორიის ფილმის შესაბამისი ჟანრის სუბდირექტორიაში ვარდება 
(მაგ. /airflow/data/images/Action/poster.jpg). იმ შემთხვევაში თუ რამდენიმე ჟანრს მიეკუთვნება ფილმი, 
პირველ ჯერზე url-დან გადმოიწერს, ვინახავ გადმოწერილი პოსტერის path-ს და ყოველი შემდეგი ჟანრისთვის 
აკოპირებს შესაბამის დირექტორიაში.

გადმოწერის პროცესები რომ დასრულდება, მერე num_epochs variable-დან ვიღებ training epoch-ების რაოდენობას
და ვუშვებ training-ს და დასრულებისას მოდელს ვინახავ. კლასების დაბალანსება და მსგავსი რაღაცები არ გამიკეთებია
რადგან არ მოგვეთხოვებოდა.

ბოლო ნაწილი BashOperator-ით airflow-შივე გავაკეთე. შენახულ მოდელს ვტვირთავ და print-ით ვბეჭდავ ყველაზე 
ალბათურ ჟანრს poster_to_predict_path variable-ში მითითებული ფაილისთვის და თითოეული ჟანრის ალბათობას.
poster_to_predict_path-ში absolute path-ის ჩაწერის დროს პირდაპირ ამ მისამართს გამოიყენებს, წინააღმდეგ
შემთხვევაში default-ად /airflow/data დირექტორია მაქვს არჩეული და მანდ მოძებნის poster_to_predict_path
მისამართზე ფაილს.